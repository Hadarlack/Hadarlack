{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vegan_Vegetarian_GlutenFree.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hadarlack/Hadarlack/blob/master/Vegan_Vegetarian_GlutenFree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5sukdB4SPkb",
        "colab_type": "text"
      },
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNNt66_cSMH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV1KqBQ7SUd1",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg__oZcXupzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX-ThYdSr46V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df\n",
        "del df1\n",
        "del df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b3520TuSW5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Read Dataset ... \")\n",
        "\n",
        "file=files.upload()\n",
        "data=pd.read_csv(\"Nutrino Food Label Challenge.csv\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz5wh_iAV-vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_KYWk1uSmLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=data # make a copy for convenience \n",
        "print(\"All Data Shape : \", df.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKmda0YAWhJx",
        "colab_type": "text"
      },
      "source": [
        "Seperate ingridients : Since Each ingredient is an import feature for the food type, I expand each ingredient into its own variable so that the model can understand whether each ingredient is present or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ1T1cXggfrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_gpd8j2l1GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(df['ingredients'].values.tolist()) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAIH5R8plII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['ingredients'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDtk0BNqieK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " vect = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split('//')], lowercase=False) # Convert a collection of text documents to a matrix of token counts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOsbO2Gcnpgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummies = vect.fit_transform(df['ingredients']) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn7S42pP2Or4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk.download()\n",
        "# nltk.download(\"stopwords\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44jEPSu31xNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import nltk\n",
        "# from nltk.corpus import stopwords\n",
        " \n",
        "# set(stopwords.words('english'))\n",
        "# stopwords = nltk.corpus.stopwords.words('english')\n",
        "# stopwords.append('regular')\n",
        "# stopwords.append('cup')\n",
        "# stopwords.append('chopped')\n",
        "# stopwords.append('whole')\n",
        "# stopwords.append('pack')\n",
        "# stopwords.append('finely')\n",
        "# stopwords.append('thinly')\n",
        "\n",
        "# from nltk.corpus import stopwords \n",
        "# from nltk.tokenize import word_tokenize "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntvqR8b--YRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word_tokens = df['ingredients'].apply(word_tokenize) \n",
        "  \n",
        "# filtered_sentence = [w for w in word_tokens if not w in stopwords] \n",
        "  \n",
        "# filtered_sentence = [] \n",
        "  \n",
        "# for w in word_tokens: \n",
        "#     if w not in stopwords: \n",
        "#         filtered_sentence.append(w) \n",
        "  \n",
        "# print(word_tokens) \n",
        "# print(filtered_sentence) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hH3bxqJo4wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " print((pd.DataFrame(dummies.toarray(),columns = vect.get_feature_names())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZpPtMBJqmxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIkc9xxZnskK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.DataFrame(dummies.todense(),columns=vect.get_feature_names())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQyLZbotnyCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list(df1.values.tolist()) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq-akJ2opX0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdDo-EBIkH7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2=pd.concat([df,df1],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzeja7DfTGpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snFjZuAPjdWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"All Data Shape: \", df2.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QArICpFFeMGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Vocab Length: \", len(vect.get_feature_names()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seCWZimjfqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Predictors: \", df.shape[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V2VWbefougs",
        "colab_type": "text"
      },
      "source": [
        "Prepare for Modeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiIuaAIUc2W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2['GlutenFree'] = pd.get_dummies(df2['GlutenFree'],drop_first=False)\n",
        "df2['Vegetarian'] = pd.get_dummies(df2['Vegetarian'],drop_first=False)\n",
        "df2['Vegan'] = pd.get_dummies(df2['Vegan'],drop_first=False)\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Ofdw5jkVHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# drop_enc = OneHotEncoder(drop='first').fit(df2['foodType'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAvh9lXN1ack",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2=df2.drop('ingredients',axis=1) # already processed\n",
        "df2=df2.drop('name',axis=1) # not helpfull\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkXB8Nv1SWU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx=df2['foodType']\n",
        "xx.nunique() # "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe8QDM2UUqcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The foodType column of the dataset has many categories and we need to reduce the number of categories for a better modelling. The foodType column has the following categories:\n",
        "\n",
        "# df2.groupby('foodType').apply(lambda x: x.nunique())#.sort_values('name')\n",
        "\n",
        "# I dont group foodTypes that can be at the same category because they dont have the same predicting values (veg, vig, glooten) and it could confuse the algorithm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncpBEA6dbe20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make foodType duumy variables - column for each type with 1/0\n",
        "cat_vars=['foodType']\n",
        "for var in cat_vars:\n",
        "  cat_list='foodType'+'_'+var\n",
        "  cat_list = pd.get_dummies(df2[var], prefix=var)\n",
        "  df3=df2.join(cat_list)\n",
        "  df2=df3\n",
        "  \n",
        "cat_vars=['foodType']\n",
        "data_vars=df2.columns.values.tolist()\n",
        "to_keep=[i for i in data_vars if i not in cat_vars]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYplCPetf1vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4=df2[to_keep]\n",
        "df4.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKy3_tvCciZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPlPV9mGSknd",
        "colab_type": "text"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHPv-YtpUOgU",
        "colab_type": "text"
      },
      "source": [
        "# Predicting Vegan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1W9t4XIURBO",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqg7uDJ8YYH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4['Vegan'].value_counts() # there are almost twice as much y=1 than y=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBIC154OYvNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(x='Vegan', data=df4)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVk1HG3YZfUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_no_veg = len(df4[df4['Vegan']==0])\n",
        "count_veg = len(df4[df4['Vegan']==1])\n",
        "pct_of_no_veg = count_no_veg/(count_no_veg+count_veg)\n",
        "print(\"percentage of no Vegans is\", pct_of_no_veg*100)\n",
        "pct_of_veg = count_veg/(count_no_veg+count_veg)\n",
        "print(\"percentage of Vegans\", pct_of_veg*100)\n",
        "#Our classes are imbalanced, and the ratio of 1:0 is 64:36. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqn5XLg6iIk2",
        "colab_type": "text"
      },
      "source": [
        "With our data created, I’ll up-sample the no-Vegan of the training set using the SMOTE algorithm (Synthetic Minority Over-sampling Technique)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0skRSuHiCQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df4.loc[:, df4.columns != 'Vegan']\n",
        "y = df4.loc[:, df4.columns == 'Vegan']\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "os = SMOTE(random_state=0) #upsampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "columns = X_train.columns\n",
        "os_data_X,os_data_y=os.fit_sample(X_train, y_train) # upsampling only the training data\n",
        "X_train = pd.DataFrame(data=os_data_X,columns=columns )\n",
        "y_train= pd.DataFrame(data=os_data_y,columns=['y'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2WIBNWJivVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"length of oversampled data is \",len(X_train))\n",
        "print(\"Number of no Vegans in oversampled data\",len(y_train[y_train['y']==0]))\n",
        "print(\"Number of Vegans in oversampled data\",len(y_train[y_train['y']==1]))\n",
        "print(\"Proportion of no Vegans data in oversampled data is \",len(y_train[y_train['y']==0])/len(X_train))\n",
        "print(\"Proportion of Vegans data in oversampled data is \",len(y_train[y_train['y']==1])/len(X_train))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK47nR-iSkn9",
        "colab_type": "text"
      },
      "source": [
        "**The models are at the bottum of the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVaLBkp5zoCR",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XYUKhfEzmp-",
        "colab_type": "text"
      },
      "source": [
        "# Predicting Vegetarian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvelMgjKzo11",
        "colab_type": "text"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rFGSrETau7D4",
        "colab": {}
      },
      "source": [
        "df4['Vegetarian'].value_counts()  # balanced classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VW4N4bjWu7EG",
        "colab": {}
      },
      "source": [
        "sns.countplot(x='Vegetarian', data=df4)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DHNxjI54u7EO",
        "colab": {}
      },
      "source": [
        "count_no_veg = len(df4[df4['Vegetarian']==0])\n",
        "count_veg = len(df4[df4['Vegetarian']==1])\n",
        "pct_of_no_veg = count_no_veg/(count_no_veg+count_veg)\n",
        "print(\"percentage of no Vegetarian is\", pct_of_no_veg*100)\n",
        "pct_of_veg = count_veg/(count_no_veg+count_veg)\n",
        "print(\"percentage of Vegetarian\", pct_of_veg*100)\n",
        "#Our classes are balanced.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PsGVfufx0aX0",
        "colab": {}
      },
      "source": [
        "X = df4.loc[:, df4.columns != 'Vegetarian']\n",
        "y = df4.loc[:, df4.columns == 'Vegetarian']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ucs6g_rwBxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qm_Dk4fd3yzO"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YkzSqqRA3yzS"
      },
      "source": [
        "# Predicting GlutenFree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Elus7-f3yzU"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8jYQ7dcJvOos",
        "colab": {}
      },
      "source": [
        "df4['GlutenFree'].value_counts() # there are almost twice as much y=0 than y=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fOd9yN1SvOo1",
        "colab": {}
      },
      "source": [
        "sns.countplot(x='GlutenFree', data=df4)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Fsf0LgBvOo5",
        "colab": {}
      },
      "source": [
        "count_no_veg = len(df4[df4['GlutenFree']==0])\n",
        "count_veg = len(df4[df4['GlutenFree']==1])\n",
        "pct_of_no_veg = count_no_veg/(count_no_veg+count_veg)\n",
        "print(\"percentage of no GlutenFree is\", pct_of_no_veg*100)\n",
        "pct_of_veg = count_veg/(count_no_veg+count_veg)\n",
        "print(\"percentage of GlutenFree\", pct_of_veg*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LMMq4sByv-33",
        "colab": {}
      },
      "source": [
        "X = df4.loc[:, df4.columns != 'GlutenFree']\n",
        "y = df4.loc[:, df4.columns == 'GlutenFree']\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "os = SMOTE(random_state=0) #upsampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "columns = X_train.columns\n",
        "os_data_X,os_data_y=os.fit_sample(X_train, y_train) # upsampling only the training data\n",
        "X_train = pd.DataFrame(data=os_data_X,columns=columns )\n",
        "y_train= pd.DataFrame(data=os_data_y,columns=['y'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-y8LmStv-4F",
        "colab": {}
      },
      "source": [
        "print(\"length of oversampled data is \",len(X_train))\n",
        "print(\"Number of no GlutenFree in oversampled data\",len(y_train[y_train['y']==0]))\n",
        "print(\"Number of GlutenFree in oversampled data\",len(y_train[y_train['y']==1]))\n",
        "print(\"Proportion of no GlutenFree data in oversampled data is \",len(y_train[y_train['y']==0])/len(X_train))\n",
        "print(\"Proportion of GlutenFree data in oversampled data is \",len(y_train[y_train['y']==1])/len(X_train))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hmcyfi6L3yzl"
      },
      "source": [
        "--------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1cYsfJnp1bh",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O67AFVjT0q3H",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0FHoO1JnYau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNr82jOmniWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-vtVld6vecJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    from sklearn import metrics\n",
        "\n",
        "print (\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, logreg.predict(X_train))) #OverFitting\n",
        "print (\"logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, logreg.predict(X_test)))    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RF5rw9intUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ0ZJBdloBqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlRflzLDvG60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission = logreg.predict(X_test)\n",
        "score = cross_validate(logreg, X_test, y_test, return_train_score=False)\n",
        "score[\"test_score\"].mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAUHM83goP4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # The receiver operating characteristic (ROC) curve \n",
        "\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "# from sklearn.metrics import roc_curve\n",
        "\n",
        "# logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "# fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "# plt.figure()\n",
        "# plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "# plt.plot([0, 1], [0, 1],'r--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.savefig('Log_ROC')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65BOxcV10sdU",
        "colab_type": "text"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpMK_lcnZYoe",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGW_-M2r0tvC",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-JBuTT9ZY9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIWvQ9cgbzwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY-RCCSIv7Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Evaluate using Cross Validation\n",
        "\n",
        "# from sklearn import model_selection\n",
        "\n",
        "# seed=7\n",
        "# num_instances = len(X_train)\n",
        "\n",
        "# kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "# # model = LogisticRegression()\n",
        "# results = model_selection.cross_val_score(logreg, X_train, y_train, cv=kfold)\n",
        "# print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfT7tV5wwffj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Evaluate using Leave One Out Cross Validation\n",
        "\n",
        "\n",
        "# num_folds = 5\n",
        "# num_instances = len(X_train)\n",
        "# loocv = model_selection.LeaveOneOut()\n",
        "# # model = LogisticRegression()\n",
        "# results = model_selection.cross_val_score(logmodel, X_train, y_train, cv=loocv)\n",
        "# print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWRulT1EvAsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# score = cross_validate(logreg, X_train, y_train, return_train_score=False)\n",
        "# score[\"test_score\"].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}